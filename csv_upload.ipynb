{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%gui asyncio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywidgets import IntSlider, Output\n",
    "import ipywidgets as widgets\n",
    "import pandas as pd\n",
    "import requests\n",
    "import asyncio\n",
    "import io\n",
    "import json\n",
    "import os\n",
    "from dateutil import parser\n",
    "from dateutil.tz import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OMF_ENDPOINT = \"http://httpbin.org/post\"\n",
    "OMF_ENDPOINT = \"https://academicpi.azure-api.net/csv-ingress/messages\"\n",
    "API_KEY = \"dummy\" \n",
    "\n",
    "def omf_type(new_type):\n",
    "    return (\n",
    "        f\"stream-{new_type}\",\n",
    "        {\n",
    "            \"id\": f\"stream-{new_type}\",\n",
    "            \"description\": \"Timestamp and real-time value\",\n",
    "            \"type\": \"object\",\n",
    "            \"classification\": \"dynamic\",\n",
    "            \"properties\": {\n",
    "                \"IndexedDateTime\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"format\": \"date-time\",\n",
    "                    \"isindex\": True,\n",
    "                },\n",
    "                \"value\": {\"type\": f\"{new_type}\"},\n",
    "            },\n",
    "        },\n",
    "    )\n",
    "\n",
    "\n",
    "omf_number_typeid, omf_number_type = omf_type(\"number\")\n",
    "\n",
    "\n",
    "def container_id(asset, name):\n",
    "    return f\"{asset}.{name}\"\n",
    "\n",
    "\n",
    "def omf_container(asset, name, typeid):\n",
    "    return {\"id\": container_id(asset, name), \"typeid\": f\"{typeid}\"}\n",
    "\n",
    "\n",
    "def omf_data(asset, name, timestamp, value):\n",
    "    ts = parser.parse(timestamp).astimezone(UTC)\n",
    "    return {\n",
    "        \"containerid\": container_id(asset, name),\n",
    "        \"values\": [{\"IndexedDateTime\": f\"{ts.isoformat()}\", \"value\": value}],\n",
    "    }\n",
    "\n",
    "\n",
    "producer_token = os.environ.get(\"PRODUCER_TOKEN\", \"osi_unitops1\")\n",
    "\n",
    "\n",
    "def omf_headers(message_type, api_key=API_KEY, producer_token=producer_token):\n",
    "    # message_type is \"type\", \"container\" or \"data\"\n",
    "    return {\n",
    "        \"producertoken\": f\"{producer_token}\",\n",
    "        \"messagetype\": f\"{message_type}\",\n",
    "        \"messageformat\": \"json\",\n",
    "        \"omfversion\": \"1.0\",\n",
    "        \"Ocp-Apim-Subscription-Key\": api_key,\n",
    "    }\n",
    "\n",
    "\n",
    "def send_omf_message(message_type, data, api_key, out=None):\n",
    "    if not isinstance(data, list):\n",
    "        data = [data]\n",
    "    if out:\n",
    "        out.append_stdout(f\"!!send_omf_message {omf_headers(message_type, api_key)}\\n\")\n",
    "        out.append_stdout(\n",
    "            f\"!!send_omf_message [{message_type}]:\\n {json.dumps(data, indent=2)}\\n\\n\"\n",
    "        )\n",
    "        return None\n",
    "\n",
    "    return requests.post(\n",
    "        OMF_ENDPOINT, headers=omf_headers(message_type, api_key), json=data\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "asset = \"Asset03\"\n",
    "sensor = \"Temp01\"\n",
    "row_batch_size = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# r = send_omf_message(\"type\", omf_number_type)\n",
    "# print(f\"type status {r.status_code} \\n ==> len={len(r.text)}: {r.text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "r = send_omf_message(\"type\", omf_number_type)\n",
    "print(f\"type status {r.status_code} \\n ==> len={len(r.text)}: {r.text}\")\n",
    "\n",
    "r = send_omf_message(\"container\", omf_container(asset, sensor, omf_number_typeid))\n",
    "print(f\"container status {r.status_code} \\n ==> len={len(r.text)}: {r.text}\")\n",
    "\n",
    "message_data = omf_data(asset, sensor, \"2020-01-29T00:00 -05:00\", -10.0)\n",
    "message_data\n",
    "\n",
    "r = send_omf_message(\"data\", omf_data(asset, sensor, \"2020-01-29T00:00 -05:00\", -10.0))\n",
    "print(f\"data status {r.status_code} \\n ==> len={len(r.text)}: {r.text}\")\n",
    "\"\"\"\n",
    "None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://academichub.blob.core.windows.net/images/logo_rgb.png\" align=\"left\" alt=\"drawing\" width=\"55\"/>\n",
    "\n",
    "##  CSV Load/Extract/Transfer for Academic Hub version 2.2\n",
    "\n",
    "### 1) Enter API key provided by OSIsoft\n",
    "### 2) Enter experiment or asset name for data\n",
    "### 3) Click `Upload` button, then select CSV file to transfer \n",
    "\n",
    "If CSV is in a valid format, progress information will show up until completion. \n",
    "\n",
    "**Note: this web application can transfer one CSV at a time. Reload this web page to restart and upload a new CSV or after an error**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wait_for_change(widget, value):\n",
    "    future = asyncio.Future()\n",
    "\n",
    "    def getvalue(change):\n",
    "        # make the new value available\n",
    "        future.set_result(change.new)\n",
    "        widget.unobserve(getvalue, value)\n",
    "\n",
    "    widget.observe(getvalue, value)\n",
    "    return future"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "462c3b3a73cd427e9223b43024272658",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='', description='API key:', placeholder='Type provided API key')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a31f33d50e240d3ae8034ef364a4573",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='', description='Experiment:', placeholder='Name of experiment or asset')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "106ccd3bb7374980b801db8da2986c41",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FileUpload(value={}, accept='.csv', description='Upload')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12615d4bbe704dd6b99c4105d83d6f56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "upload = widgets.FileUpload(accept=\".csv\")\n",
    "api_key = widgets.Text(\n",
    "    value=\"\",\n",
    "    placeholder=\"Type provided API key\",\n",
    "    description=\"API key:\",\n",
    "    disabled=False,\n",
    ")\n",
    "experiment = widgets.Text(\n",
    "    value=\"\",\n",
    "    placeholder=\"Name of experiment or asset\",\n",
    "    description=\"Experiment:\",\n",
    "    disabled=False,\n",
    ")\n",
    "out = Output()\n",
    "\n",
    "\n",
    "def load_extract_transfer(value, api_key, timezone=\"-07:00\"):\n",
    "    r = send_omf_message(\"type\", omf_number_type, api_key)\n",
    "    if r.status_code != 200:\n",
    "        if r.status_code == 401:\n",
    "            out.append_stdout(f\"@@ please correct API key: current key is {api_key}\\n\")\n",
    "        else:\n",
    "            out.append_stdout(\n",
    "                f\"\\n\\n !#!# error with type definition: status={r.status_code}\\n\\n >>> {r.text}\\n\\n\"\n",
    "        )\n",
    "        return \"@@error with OMF type or API key, reload URL\"\n",
    "    else:\n",
    "        out.append_stdout(\">> OMF type definition OK\\n\")\n",
    "\n",
    "    # print(f\"type status {r.status_code} \\n ==> len={len(r.text)}: {r.text}\")\n",
    "    asset = experiment.value\n",
    "    if len(asset) == 0:\n",
    "        out.append_stdout(\"@@ experiment/asset name should not be empty\\n\")\n",
    "        return \"error: experiment/asset name is empty\"\n",
    "    file_key = list(value.keys())[0]\n",
    "    out.append_stdout(f\">> Filename: {file_key} \" + \"\\n\")\n",
    "    data = value[file_key][\"content\"].decode(\"utf-8\")\n",
    "    df = pd.read_csv(io.StringIO(data))\n",
    "\n",
    "    fixed_column_names = [x.replace(\".\", \"_\") for x in list(df.columns)]\n",
    "    df.columns = fixed_column_names\n",
    "    # out.append_stdout(f\"\\n\\n @@Columns: {fixed_column_names}\\n\")\n",
    "    buf = io.StringIO()\n",
    "    df.info(buf=buf)\n",
    "    out.append_stdout(\n",
    "        f\"\\n------ Info about Dataframe built from CSV ------- \\n\"\n",
    "        + str(buf.getvalue())\n",
    "        + \"\\n\\n\"\n",
    "    )\n",
    "    #\n",
    "    # First two columns for Utah are Date and Time, so skip them\n",
    "    #\n",
    "    containers = [\n",
    "        omf_container(asset, sensor, omf_number_typeid)\n",
    "        for sensor in list(df.columns)[2:]\n",
    "    ]\n",
    "    r = send_omf_message(\"container\", containers, api_key)  # , out=out)\n",
    "    if r.status_code != 200:\n",
    "        out.append_stdout(\n",
    "            f\"\\n\\n !#!# error with column definition: status={r.status_code}\\n\\n >>> {r.text}\\n\\n\"\n",
    "        )\n",
    "        return \"@@error with OMF containers\"\n",
    "    else:\n",
    "        out.append_stdout(\">> column definitions OK\\n\")\n",
    "\n",
    "    count = 0\n",
    "    out.append_stdout(\">> processing row: \")\n",
    "    row_batch_data = []\n",
    "    for r in df.itertuples():\n",
    "        row_dict = r._asdict()\n",
    "        #\n",
    "        # Time format is HH:MM:SS:ss, needs to be HH:MM:SS.ss\n",
    "        #\n",
    "        last_colon = r.Time.rfind(\":\")\n",
    "        new_time = r.Time[:last_colon] + \".\" + r.Time[last_colon + 1 :]\n",
    "        # out.append_stdout(f\"new_time = {new_time}\\n\")\n",
    "        t = parser.parse(r.Date + \" \" + new_time + \" \" + timezone)\n",
    "        # out.append_stdout(f\"## {t.astimezone(UTC).isoformat()} \\n\")\n",
    "\n",
    "        row_omf_data = [\n",
    "            omf_data(asset, sensor, t.astimezone(UTC).isoformat(), row_dict[sensor])\n",
    "            for sensor in list(df.columns)[2:]\n",
    "        ]\n",
    "        # out.append_stdout(f\"row omf data: {row_omf_data}\\n\")\n",
    "        count += 1\n",
    "        row_batch_data.extend(row_omf_data)\n",
    "        if count % row_batch_size == 0:\n",
    "            out.append_stdout(f\"[{count}]\")\n",
    "            r = send_omf_message(\"data\", row_batch_data, api_key)  # , out=out)\n",
    "            row_batch_data = []\n",
    "            if r:\n",
    "                if r.status_code != 200:\n",
    "                    out.append_stdout(\n",
    "                        f\"\\n\\n !#!# error with row #{count}: status={r.status_code}\\n\\n >>> {r.text}\\n\\n\"\n",
    "                    )\n",
    "    out.append_stdout(f\"[last rows {len(row_batch_data)}]\\n\")\n",
    "    if len(row_batch_data) > 0:\n",
    "        r = send_omf_message(\"data\", row_batch_data, api_key)  # , out=out)\n",
    "        if r.status_code != 200:\n",
    "            out.append_stdout(\n",
    "                f\"\\n\\n !#!# error with last rows #{count}: status={r.status_code}\\n\\n >>> {r.text}\\n\\n\"\n",
    "            )\n",
    "        else:\n",
    "            out.append_stdout(\n",
    "                f\"\\n\\nLoading-Extract-Transfer to Hub done, status OK, #rows = {count}\\n\"\n",
    "            )\n",
    "    else:\n",
    "        out.append_stdout(\"[no more data]\\n\")\n",
    "\n",
    "    return f\"OK {file_key}\"\n",
    "\n",
    "\n",
    "async def f():\n",
    "    out.append_stdout(\"Click *Upload* button to select CSV file for transfer to Hub \\n\")\n",
    "    x = await wait_for_change(upload, \"value\")\n",
    "    out.append_stdout(\n",
    "        \"working on load, extract and tranfer... \"\n",
    "        + str(list(upload.value.keys())[0])\n",
    "        + \"\\n\"\n",
    "    )\n",
    "    status = load_extract_transfer(upload.value, api_key=api_key.value)\n",
    "    out.append_stdout(f\"Upload status {status}\\n\")\n",
    "\n",
    "\n",
    "asyncio.ensure_future(f())\n",
    "\n",
    "display(api_key)\n",
    "display(experiment)\n",
    "display(upload)\n",
    "display(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
